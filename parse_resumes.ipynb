{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import shutil  # For moving files\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/app/\"\n",
    "doc_folder = root + \"resumes/\"\n",
    "#vector_db_path = root + \"/data-ingestion-local/\"\n",
    "vector_db_path = root + \"resumes_vector_db/\"\n",
    "embed_model_name = \"all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_resumes(doc_folder):\n",
    "    pdfs = [pdf for pdf in os.listdir(doc_folder) if pdf.endswith(\".pdf\")]\n",
    "    if len(pdfs) == 0:\n",
    "        if debug:\n",
    "            print(\"No PDF files found in the folder. Exiting...\")\n",
    "        return -1\n",
    "    else:\n",
    "        if debug:\n",
    "            print(pdfs)\n",
    "        doc_container = []\n",
    "        archive_dir = os.path.join(doc_folder, \"_archive\")\n",
    "        for pdf in pdfs:\n",
    "            if os.path.exists(os.path.join(archive_dir, \"processed_files.txt\")):\n",
    "                with open(os.path.join(archive_dir, \"processed_files.txt\"), \"r\") as f:\n",
    "                    processed_files = f.read().splitlines()\n",
    "            else:\n",
    "                processed_files = []\n",
    "\n",
    "            if pdf in processed_files:\n",
    "                if debug:\n",
    "                    print(f\"File {pdf} has already been processed. Skipping...\")\n",
    "                continue\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"Processing file {pdf}...\")\n",
    "                loader = PyPDFLoader(os.path.join(doc_folder, pdf),\n",
    "                                extract_images=False)\n",
    "                docsRaw = loader.load()\n",
    "                for doc in docsRaw:\n",
    "                    doc_container.append(doc)\n",
    "                # Store the processed file name in a text file\n",
    "                metadata_folder = os.path.join(doc_folder, \"_metadata\")\n",
    "                if not os.path.exists(metadata_folder):\n",
    "                    os.makedirs(metadata_folder)\n",
    "                with open(os.path.join(metadata_folder, \"processed_files.txt\"), \"a\") as f:\n",
    "                    f.write(pdf + \"\\n\")\n",
    "                \n",
    "                # Move the processed file to archive_dir folder\n",
    "                \n",
    "                if not os.path.exists(archive_dir):\n",
    "                    os.makedirs(archive_dir)\n",
    "                shutil.move(os.path.join(doc_folder, pdf), archive_dir)\n",
    "        \n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "        docs_split = splitter.split_documents(documents=doc_container)\n",
    "        if debug:\n",
    "            print(docs_split[0])\n",
    "            print(\"\\n--- Document Chunks Information ---\", end=\"\\n\")\n",
    "            print(f\"Number of document chunks: {len(docs_split)}\", end=\"\\n\\n\")\n",
    "        return docs_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_db(docs_split, vector_db_path):\n",
    "    if docs_split == -1:\n",
    "        print(\"No documents to process.\")\n",
    "    else:\n",
    "        embedF = HuggingFaceEmbeddings(model_name = embed_model_name)\n",
    "        if debug:    \n",
    "            print(\"[INFO] Started embedding\", end=\"\\n\")\n",
    "        start = time.time()\n",
    "        vectorDB = Chroma.from_documents(documents=docs_split,\n",
    "                                        embedding=embedF,\n",
    "                                        persist_directory=vector_db_path)\n",
    "        end = time.time()\n",
    "        if debug:\n",
    "            print(f\"Time taken to embed: {end - start} seconds\")\n",
    "        print(\"Vector Database created successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_existing_vector_database(docs_split, vector_db_path):\n",
    "    if docs_split == -1:\n",
    "        print(\"No documents to process.\")\n",
    "    else:\n",
    "        if debug:\n",
    "            print(\"[INFO] Started embedding and adding data to existing database\", end=\"\\n\")\n",
    "        embedF = HuggingFaceEmbeddings(model_name=embed_model_name)\n",
    "        vectorDB = Chroma(persist_directory=vector_db_path, embedding_function=embedF)\n",
    "        vectorDB.add_documents(docs_split)\n",
    "        vectorDB.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No PDF files found in the folder. Exiting...\n",
      "Vector Database Already Exists\n",
      "No documents to process.\n"
     ]
    }
   ],
   "source": [
    "docs_split = process_resumes(doc_folder)\n",
    "if not os.path.exists(vector_db_path):\n",
    "    if debug:\n",
    "        print(\"Vector Database does not exist\")\n",
    "    create_vector_db(docs_split, vector_db_path)\n",
    "else:\n",
    "    if debug:\n",
    "        print(\"Vector Database Already Exists\")\n",
    "    add_to_existing_vector_database(docs_split, vector_db_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
